{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data and package imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas import Series, DataFrame\n",
    "import matplotlib.pyplot as plt\n",
    "import psycopg2 as pg\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import dbcreds\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "import sklearn\n",
    "from sklearn.metrics import precision_recall_curve, auc\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from sklearn.ensemble import (RandomForestClassifier, ExtraTreesClassifier, GradientBoostingClassifier, \n",
    "AdaBoostClassifier)\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "#from .utils import db_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#TO's iefp_data_utils\n",
    "\n",
    "#Cleans application data\n",
    "    #Removes applications of people whose application date is after max_start_date\n",
    "    #Removes applications of people who are already employed/part-time employed\n",
    "#Sample Usage: clean_apps=clean_applications(apps_df,'2016-04-31')\n",
    "def clean_applications(applications,max_start_date):\n",
    "    clean_apps = applications.copy()\n",
    "    clean_apps['app_start_date'] = pd.to_datetime(clean_apps['anomes'],format=\"%Y%m\")\n",
    "    clean_apps = clean_apps[clean_apps['app_start_date'] <= max_start_date]\n",
    "    clean_apps = clean_apps[~clean_apps['dcategoria'].isin(['EMPREGADO', 'EMPREGADO A TEMPO PARCIAL'])] \n",
    "    clean_apps = clean_apps.sort_values(['ute_id','app_start_date'])\n",
    "    return clean_apps\n",
    "\n",
    "\n",
    "#Cleans and Filters movements data\n",
    "    #Removes movements that don't start with an application\n",
    "    #If apps_series parameter is present, filters the movements which do not belong to the applications in the series\n",
    "#Sample Usage: clean_movs=clean_movements(movements)\n",
    "#              clean_movs=clean_movements(movements,apps['table_index']) \n",
    "def clean_movements(movements, apps_series=None):\n",
    "    clean_data = movements.copy()\n",
    "    clean_data = clean_data[clean_data['application_id'] != -1] #Removing movements that don't start with an application\n",
    "    if not apps_series is None: \n",
    "        clean_data = clean_data[clean_data['application_id'].isin(apps_series)]\n",
    "    clean_data = clean_data.sort_values(['ute_id','year_month','movement_date'])\n",
    "    return clean_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class color:\n",
    "   PURPLE = '\\033[95m'\n",
    "   CYAN = '\\033[96m'\n",
    "   DARKCYAN = '\\033[36m'\n",
    "   BLUE = '\\033[94m'\n",
    "   GREEN = '\\033[92m'\n",
    "   YELLOW = '\\033[93m'\n",
    "   RED = '\\033[91m'\n",
    "   BOLD = '\\033[1m'\n",
    "   UNDERLINE = '\\033[4m'\n",
    "   END = '\\033[0m'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conn = pg.connect(dbname = dbcreds.database, host=dbcreds.host, user=dbcreds.user, password = dbcreds.password)\n",
    "apps_df = pd.read_sql('select * from cascais.application', con=conn)\n",
    "move_df = pd.read_sql('select * from cascais.movement', con=conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter data to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create datetime objects for applications from candidatura_data\n",
    "apps_df.loc[:,'date']= apps_df.loc[:,'candidatura_data'].apply(\n",
    "    lambda x: None if x=='' else datetime(year=int(x[0:4]),\n",
    "                       month=int(x[5:7]),\n",
    "                       day=int(x[8:10])))\n",
    "\n",
    "#create datetime objects for cancellations,\n",
    "# and placeholder dates for movements that aren't cancellations\n",
    "def create_date(series):\n",
    "    if series['movement_date'] == '':\n",
    "        return datetime(year=int(str(series['year_month'])[0:4]),\n",
    "                        month = int(str(series['year_month'])[4:6]),\n",
    "                        day = 15)\n",
    "    else:\n",
    "        return datetime(year=int(series['movement_date'][0:4]),\n",
    "                       month=int(series['movement_date'][5:7]),\n",
    "                       day=int(series['movement_date'][8:10]))\n",
    "\n",
    "move_df.loc[:, 'date'] = move_df.apply(create_date, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#fill NAs for descendents\n",
    "apps_df.loc[:,'ute_nr_descendentes_cargo'].fillna(0.0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Identify application IDs that are associated with applications submitted after\n",
    "# April 2016 - to allow for 1 year of follow-up data\n",
    "apps_not_late = apps_df[apps_df['date']<=datetime(2016, 4, 28)].loc[:,'table_index'].tolist()\n",
    "\n",
    "apps_df = apps_df[apps_df['table_index'].isin(apps_not_late)]\n",
    "move_df = move_df[move_df['application_id'].isin(apps_df['table_index'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Identify applications IDs that were not unemployed\n",
    "apps_df.dcategoria.value_counts()\n",
    "apps_df = apps_df[apps_df['dcategoria'].isin(['DESEMPREGADO-NOVO EMPREGO',\n",
    "                                            'DESEMPREGADO-1Âº EMPREGO'])]\n",
    "move_df = move_df[move_df['application_id'].isin(apps_df['table_index'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_labels(apps_df, move_df):\n",
    "    # Create dictionary of appliction dates\n",
    "    app_date_dict = dict(zip(apps_df['table_index'], apps_df['date']))\n",
    "    \n",
    "    # Create time since app variable\n",
    "    move_df.loc[:, 'app_date'] = move_df.loc[:, 'application_id'].map(app_date_dict)\n",
    "    move_df.loc[:, 'time_since_app'] = move_df.loc[:, 'date'] - move_df.loc[:, 'app_date']\n",
    "\n",
    "    # Identify applications that had an interview placement within 12 months\n",
    "    apps_placed_interview = move_df[(move_df['movement_result']=='ADMITIDO / COLOCADO') \\\n",
    "                                & (move_df['time_since_app']<=timedelta(days=365))].\\\n",
    "    application_id.unique().tolist()\n",
    "    \n",
    "    # Identify applications that had a cancellation for becoming employed within 12 months\n",
    "    employed_cancellations = ['COLOCAÃÃO POR MEIOS PRÃPRIOS, POR CONTA DE OUTREM',\n",
    "                         'COLOCAÃÃO POR MEIOS PRÃPRIOS, POR CONTA PRÃPRIA',\n",
    "                         'COLOCAÃÃO - CANDIDATURA EXTERNA'\n",
    "                         'COLOCAÃÃO - CANDIDATURA INTERNA']\n",
    "\n",
    "    apps_placed_cancellation = move_df[(move_df['movement_subtype'].isin(employed_cancellations)) \\\n",
    "                                & (move_df['time_since_app']<=timedelta(days=365))].\\\n",
    "    application_id.unique().tolist()\n",
    "\n",
    "    # Create list for applications that found a job within 12 months\n",
    "    apps_found_job_12 = apps_placed_interview + apps_placed_cancellation\n",
    "    \n",
    "    # Identify applications that had any cancellation within 12 months\n",
    "    apps_cancelled_12 = move_df[(move_df['movement_type']=='cancellation') \\\n",
    "                                & (move_df['time_since_app']<=timedelta(days=365))].\\\n",
    "    application_id.unique().tolist()\n",
    "    \n",
    "    # grab unique app IDs and put into index\n",
    "    labels_df = apps_df.rename(columns = {'table_index':'application_id'})\n",
    "    labels_df = labels_df.groupby(['application_id', 'date'])['ute_id', 'anomes'].count()    \n",
    "\n",
    "    #create intermediate variables found_job_12 and cancelled _12\n",
    "    labels_df.loc[:,'found_job_12'] = labels_df.index.get_level_values(level='application_id').isin(apps_found_job_12)\n",
    "    labels_df.loc[:,'canceled_12'] = labels_df.index.get_level_values(level='application_id').isin(apps_cancelled_12)\n",
    "    \n",
    "    #create labels, set application ID as the index, and drop intermediate variables\n",
    "    #label is True if application is LTU\n",
    "    labels_df.loc[:, 'label'] = ~labels_df.loc[:, 'found_job_12'] & ~labels_df.loc[:, 'canceled_12']\n",
    "    labels_df.drop (['found_job_12', 'canceled_12', 'ute_id', 'anomes'], axis=1, inplace=True)\n",
    "\n",
    "    return labels_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def demographic_features(apps_df, column_names):\n",
    "    apps_df_small = apps_df.rename(columns={'table_index': 'application_id'})\n",
    "    apps_df_small = apps_df_small.groupby(['application_id', 'date']).first()\n",
    "    apps_df_small = apps_df_small[column_names]\n",
    "\n",
    "    return apps_df_small\n",
    "\n",
    "def clean_matrix(m):\n",
    "    # generate dummies for categorical values\n",
    "    m = pd.get_dummies(m, drop_first=True)\n",
    "    return m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binding Features to Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_data(apps_df, move_df, f_demo, start_date, run_date, follow_up=365):\n",
    "    \n",
    "    # get timestamps for split\n",
    "    start_date = pd.to_datetime(start_date)\n",
    "    run_date = pd.to_datetime(run_date)\n",
    "    split_date = run_date - timedelta(days=follow_up)\n",
    "    \n",
    "    # create lables and features\n",
    "    labels = generate_labels(apps_df, move_df)\n",
    "    features_demographic = demographic_features(apps_df, f_demo)\n",
    "    \n",
    "    # bind labels and features\n",
    "    m = labels\n",
    "    for f in [features_demographic]:\n",
    "        m = m.merge(f, how = 'left', left_index=True, right_index=True)\n",
    "    \n",
    "    # create a training set and test set based on split date\n",
    "    m_train = m.iloc[(m.index.get_level_values('date')<split_date) & (m.index.get_level_values('date')>=start_date), :] \n",
    "    m_test = m.iloc[m.index.get_level_values('date')>=split_date, :]\n",
    "    \n",
    "    return clean_matrix(m_train), clean_matrix(m_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m_train, m_test = split_data(apps_df, move_df, ['sexo', 'ute_idade', 'sub_rsi'],\n",
    "                             start_date = '1994-01-01', run_date = '2020-01-01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = m_train.drop('label', 1)\n",
    "y_train = m_train.label.astype(float)\n",
    "estimator = RandomForestClassifier(n_estimators = 100,\n",
    "                   criterion = 'gini',\n",
    "                   max_depth = None,\n",
    "                   random_state = 4321)\n",
    "#estimator.fit(X=X_train, y=y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_RF(apps_df, move_df, f_demo, start_date, run_date, follow_up=365,\n",
    "          n_estimators=100, max_depth=None, random_state=4321, p_threshold=0.5):\n",
    "    \n",
    "    # get the test and train data splits\n",
    "    m_train, m_test = split_data(apps_df, move_df, f_demo, start_date, run_date, follow_up)\n",
    "    \n",
    "    X_train = m_train.drop('label', 1)\n",
    "    y_train = m_train.label.astype(float)\n",
    "\n",
    "    X_test = m_test.drop('label', 1)\n",
    "    y_test = m_test.label.astype(float)\n",
    "\n",
    "    #create and fit the estimator on training set\n",
    "    estimator = RandomForestClassifier(n_estimators = n_estimators,\n",
    "                       criterion = 'gini',\n",
    "                       max_depth = max_depth,\n",
    "                       random_state = random_state)\n",
    "    \n",
    "    estimator.fit(X=X_train, y=y_train)\n",
    "    \n",
    "    #generate predicted y values on test set\n",
    "    y_predict = estimator.predict_proba(X=X_test)\n",
    "    y_predict_prob = pd.Series(index=X_test.index, data=y_predict[:,1])\n",
    "    y_predict_class = y_predict_prob.apply(lambda x: 1 if x>=p_threshold else 0)\n",
    "    \n",
    "    #calculate metrics\n",
    "    accuracy = sklearn.metrics.accuracy_score(y_test, y_predict_class)\n",
    "    accuracy_base = max (m_test.label.mean(), 1-m_test.label.mean())\n",
    "    precision = sklearn.metrics.precision_score(y_test, y_predict_class)\n",
    "    return (accuracy, accuracy_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.68156691462499142, 0.69272503924111106)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_RF(apps_df, move_df, f_demo = ['sexo', 'ute_idade', 'sub_rsi'],\n",
    "       start_date = '2011-01-01', run_date = '2015-01-01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
