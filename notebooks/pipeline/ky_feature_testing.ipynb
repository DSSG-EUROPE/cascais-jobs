{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda/lib/python2.7/site-packages/statsmodels/compat/pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  from pandas.core import datetools\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "from pandas import Series, DataFrame\n",
    "from datetime import datetime\n",
    "from calendar import monthrange\n",
    "sys.path.append(\"../../\")\n",
    "from utils import model_utils\n",
    "from utils import db_utils\n",
    "from utils import feature_utils\n",
    "from utils import iefp_data_utils\n",
    "from utils import pandas_utils\n",
    "from sklearn import preprocessing\n",
    "\n",
    "import math\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "## for testing - don't include in final script\n",
    "import datetime\n",
    "\n",
    "def timestamp():\n",
    "    global x\n",
    "    y=x\n",
    "    x=datetime.datetime.now()\n",
    "    return str(datetime.datetime.now()-y)\n",
    "\n",
    "from utils import model_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from calendar import monthrange\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "def monthdelta(d1, d2):\n",
    "    delta = 0\n",
    "    while True:\n",
    "        mdays = monthrange(d1.year, d1.month)[1]\n",
    "        d1 += timedelta(days=mdays)\n",
    "        if d1 <= d2:\n",
    "            delta += 1\n",
    "        else:\n",
    "            break\n",
    "    return delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating LTU/Non-LTU labels\n"
     ]
    }
   ],
   "source": [
    "conn = db_utils.connect_to_db()\n",
    "apps,movs = iefp_data_utils.get_clean_data(conn)\n",
    "labelled_apps = feature_utils.get_ltu_label(apps,movs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Demographic feature functions\n",
    "def apps_cancelled_within_n_months(x,n=12):\n",
    "    return x[(x['movement_type'].isin(['cancellation'])) & (x['months_after_app'] < n)]['application_id'].unique()\n",
    "\n",
    "def apps_placed_within_n_months(x,n=12):\n",
    "    return x[(x['movement_result'].isin(['ADMITIDO / COLOCADO'])) & (x['months_after_app'] < n)]['application_id'].unique()\n",
    "\n",
    "#Add column to show how many months after the application the movement occurred\n",
    "def monthdelta(d1, d2):\n",
    "    delta = 0\n",
    "    while True:\n",
    "        mdays = monthrange(d1.year, d1.month)[1]\n",
    "        d1 += timedelta(days=mdays)\n",
    "        if d1 <= d2:\n",
    "            delta += 1\n",
    "        else:\n",
    "            break\n",
    "    return delta\n",
    "\n",
    "def difftime_in_months(timeA,timeB):\n",
    "    return (timeA-timeB)/np.timedelta64(1, 'M')\n",
    "\n",
    "\n",
    "def get_ltu_label(apps,movs):\n",
    "    app_date_dict = dict(zip(apps[\"table_index\"],apps[\"app_start_date\"]))\n",
    "    movs[\"app_start_date\"] = movs[\"application_id\"].map(app_date_dict)\n",
    "    movs[\"months_after_app\"] = difftime_in_months(movs[\"movement_event_date\"],movs[\"app_start_date\"])\n",
    "    \n",
    "    print \"Generating LTU/Non-LTU labels\"\n",
    "    cancelled_12mo = apps_cancelled_within_n_months(movs)\n",
    "    placed_12mo = apps_placed_within_n_months(movs)\n",
    "    \n",
    "    non_ltu_apps = np.unique(np.append(cancelled_12mo,placed_12mo))\n",
    "    apps['ltu'] = np.logical_not(apps['table_index'].isin(non_ltu_apps))\n",
    "    last_data_date = max(apps['app_start_date'])\n",
    "    apps.loc[difftime_in_months(last_data_date,apps['app_start_date']) < 12,'ltu'] = False\n",
    "    \n",
    "    return apps\n",
    "\n",
    "def findSeason(x):\n",
    "    month=x.month\n",
    "    if month in [12,1,2]:\n",
    "        return \"Winter\"\n",
    "    if month in [3,4,5]:\n",
    "        return \"Spring\"\n",
    "    if month in [6,7,8]:\n",
    "        return \"Summer\"\n",
    "    if month in [9,10,11]:\n",
    "        return \"Autumn\"\n",
    "\n",
    "def isPortuguese(x):\n",
    "    if x==\"PT\":\n",
    "        return \"PT\"\n",
    "    else:\n",
    "        return \"OT\"\n",
    "\n",
    "def lookingForFirstJob(x):\n",
    "    if \"NOVO\" in x:\n",
    "        return \"first_job\"\n",
    "    else:\n",
    "        return \"not_first_job\"\n",
    "\n",
    "def createEducationBuckets(x):\n",
    "    HS=[\"12\"]\n",
    "    #SL means  able to write, but no school degree,NS means not able to write\n",
    "    NR=[\"NS\"]\n",
    "    U6=[\"SL\",\"04\",\"06\"]\n",
    "    U11=[\"09\",\"11\"]\n",
    "    \n",
    "    #The rest is different kinds of higher degree\n",
    "    if x in HS:\n",
    "        return \"HS\"\n",
    "    if x in NR:\n",
    "        return \"NR\"\n",
    "    if x in U6:\n",
    "        return \"U6\"\n",
    "    if x in U11:\n",
    "        return \"U11\"\n",
    "    else:\n",
    "        return \"MHS\"\n",
    "\n",
    "def civilStatus(x):\n",
    "    if x==\"S\":\n",
    "        return \"S\"\n",
    "    if x==\"C\":\n",
    "        return \"M\"\n",
    "    else :\n",
    "        return \"O\"\n",
    "\n",
    "def ageBucket(x):\n",
    "    if x<30:\n",
    "        return \"age<30\"\n",
    "    elif x<50:\n",
    "        return \"30<age<50\"\n",
    "    else:\n",
    "        return \"age>50\"\n",
    "\n",
    "def findMainBucket(profession):\n",
    "    profDict={0:\"Miliatary\",1:\"Managment\",2:\"Higer level professionals\",3:\"Lower level professionals\",4:\"Office jobs\",5:\"Sales\",\n",
    "              6:\"Fising and farming\",7:\"Craft and trade\",8:\"Factory work\",9:\"Elementary\"}\n",
    "    if pd.isnull(profession):\n",
    "        return \"Unknown\"\n",
    "    else:\n",
    "        professionInt=int(str(profession)[0:1])\n",
    "        return profDict[professionInt]\n",
    "    \n",
    "def findMainEducation(education):\n",
    "    eduDict={0:\"general\",1:\"Education\",2:\"ArtsAndHumanities\",3:\"SocialScienceTradeAndLaw\",4:\"STEM\",5:\"EngineeringAndConstruction\",6:\"Agriculture\",7:\"HealthAndSocialProtection\",8:\"Service\",9:\"Unkown\"}\n",
    "    if pd.isnull(education):\n",
    "        return eduDict[9]\n",
    "    else:\n",
    "        professionInt=int(str(education)[0:1])\n",
    "        return eduDict[professionInt]\n",
    "\n",
    "def preferredJobRegion(letter):\n",
    "    if letter == \"C\":\n",
    "        return \"NearJobCenter\"\n",
    "    elif letter == \"R\":\n",
    "        return \"GreaterLisbonArea\"\n",
    "    elif letter == \"N\":\n",
    "        return \"Available\"\n",
    "    elif pd.isnull(letter):\n",
    "        return \"Unknown\"\n",
    "    else:\n",
    "        return \"Error\"\n",
    "\n",
    "def employmentPlan(letter):\n",
    "    if letter == \"S\":\n",
    "        return \"exists\"\n",
    "    elif letter ==\"N\":\n",
    "        return \"no plan\"\n",
    "    else:\n",
    "        return \"Error\"\n",
    "    \n",
    "def applicationOrigin(origin):\n",
    "    if origin == \"SIGAE\":\n",
    "        return \"SIGAE\"\n",
    "    elif origin == \"LSE\":\n",
    "        return \"LSE\"\n",
    "    elif pd.isnull(origin):\n",
    "        return \"unknown\"\n",
    "    else:\n",
    "        return \"Error\"\n",
    "    \n",
    "def intendedRegime(regime):\n",
    "    if regime == \"COMPLETO\":\n",
    "        return \"Full-time\"\n",
    "    elif regime == \"PARCIAL\":\n",
    "        return \"Part-time\"\n",
    "    else:\n",
    "        return \"Error\"\n",
    "\n",
    "def dependentsBucket(n):\n",
    "    if n == 0:\n",
    "        return \"0\"\n",
    "    elif n == 1:\n",
    "        return \"1\"\n",
    "    elif n == 2:\n",
    "        return \"2\"\n",
    "    elif n == 3:\n",
    "        return \"3\"\n",
    "    elif pd.isnull(n):\n",
    "        return \"Unknown\"\n",
    "    else:\n",
    "        return \"4+\"\n",
    "    \n",
    "def experienceBuckets(n):\n",
    "    if pd.isnull(n):\n",
    "        return \"Unknown\"\n",
    "    elif n == 0:\n",
    "        return \"0\"\n",
    "    elif n<24:\n",
    "        return \"<2yr\"\n",
    "    elif n<60:\n",
    "        return \"<5yr\"\n",
    "    elif n<120:\n",
    "        return \"<10yr\"\n",
    "    elif n<240:\n",
    "        return \"<20yr\"\n",
    "    else:\n",
    "        return \"20+yr\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Variables definitions\n",
    "feature_set_name = 'dynamic'\n",
    "train_st_date = pd.to_datetime('2015-04-30')\n",
    "test_st_date = pd.to_datetime('2016-04-30')\n",
    "test_window_size = pd.Timedelta('365D')\n",
    "ltu_length = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Functions definitions\n",
    "def split_train_test_apps(apps_df,movs_df,test_date,train_start_date,ltu_length):\n",
    "    selected_apps = model_utils.filter_by_time_range(apps_df,'app_start_date',train_start_date,test_date).sort_values('app_start_date')\n",
    "    selected_movs = model_utils.filter_by_time_range(movs_df,'movement_event_date',train_start_date,test_date).sort_values('movement_event_date')\n",
    "    exitted = model_utils.apps_exited_before_date(selected_movs,test_date)\n",
    "    test_apps = selected_apps[(np.logical_not(selected_apps['table_index'].isin(exitted))) &\n",
    "                              (pandas_utils.difftime_in_months(test_date,selected_apps['app_start_date']) < ltu_length)]\n",
    "    \n",
    "    train_apps = selected_apps[(np.logical_not(selected_apps['table_index'].isin(test_apps['table_index'])))]\n",
    "    \n",
    "    train_movs = selected_movs[(np.logical_not(selected_movs['application_id'].isin(test_apps['table_index'])))]\n",
    "    return train_apps, test_apps, train_movs\n",
    "\n",
    "def get_cancellation_date(x):\n",
    "    return x[x['movement_type'].isin(['cancellation'])].sort_values('movement_event_date').groupby(['application_id']).first().reset_index()[['application_id','movement_event_date']].rename(columns={'movement_event_date': 'cancellation_date'})\n",
    "\n",
    "def get_placement_date(x):\n",
    "    return x[x['movement_result'].isin(['ADMITIDO / COLOCADO'])].sort_values('movement_event_date').groupby(['application_id']).first().reset_index()[['application_id','movement_event_date']].rename(columns={'movement_event_date': 'placement_date'})\n",
    "\n",
    "def get_last_active_date(apps,movs,ref_date):\n",
    "    apps_cancellations = get_cancellation_date(movs)\n",
    "    apps_placements = get_placement_date(movs)\n",
    "    apps_length = apps.merge(apps_cancellations,how='left', left_on='table_index',right_on='application_id').merge(apps_placements,how='left', left_on='table_index',right_on='application_id')[['table_index','app_start_date','cancellation_date','placement_date']]\n",
    "    apps_length['ref_date'] = ref_date\n",
    "    apps_length['last_active_date'] = apps_length[['cancellation_date', 'placement_date','ref_date']].min(axis=1)\n",
    "    \n",
    "    return apps_length[['table_index','app_start_date','last_active_date']]    \n",
    "\n",
    "def get_app_length(apps,movs,ref_date=None):\n",
    "    apps_last_active_date = get_last_active_date(train_apps,movs,ref_date)\n",
    "    apps_last_active_date['app_length'] = apps_last_active_date['last_active_date'] - apps_last_active_date['app_start_date']\n",
    "    \n",
    "    return apps_last_active_date\n",
    "\n",
    "def extend_data(apps,movs,labels,ref_date,time_delta):\n",
    "    apps_length = get_app_length(apps,movs,ref_date)\n",
    "    apps_length = apps_length.merge(labels,on='table_index')\n",
    "    toDataFrame=[]\n",
    "    for i in xrange(0,apps_length.shape[0]):\n",
    "        app_id = apps_length['table_index'][i]\n",
    "        app_st_date = apps_length['app_start_date'][i]\n",
    "        app_length = apps_length['app_length'][i]\n",
    "        app_label = apps_length['ltu'][i]\n",
    "        for j in xrange(0,int(math.ceil(app_length/pd.Timedelta('30D')))+1):\n",
    "            toDataFrame.append([app_id,app_st_date,app_st_date + (j*relativedelta(months=1)),app_label])\n",
    "    extended_data = pd.DataFrame(toDataFrame,columns=['application_id','app_start_date','ref_date','ltu'])\n",
    "    return extended_data\n",
    "\n",
    "def apps_cancelled_within_n_months(x,n=12):\n",
    "    return x[(x['movement_type'].isin(['cancellation'])) & (x['months_after_app'] < n)]['application_id'].unique()\n",
    "\n",
    "def apps_placed_within_n_months(x,n=12):\n",
    "    return x[(x['movement_result'].isin(['ADMITIDO / COLOCADO'])) & (x['months_after_app'] < n)]['application_id'].unique()\n",
    "\n",
    "def difftime_in_months(timeA,timeB):\n",
    "    return (timeA-timeB)/np.timedelta64(1, 'M')\n",
    "\n",
    "def get_ltu_label(apps,movs):\n",
    "    app_date_dict = dict(zip(apps[\"table_index\"],apps[\"app_start_date\"]))\n",
    "    movs[\"app_start_date\"] = movs[\"application_id\"].map(app_date_dict)\n",
    "    movs[\"months_after_app\"] = difftime_in_months(movs[\"movement_event_date\"],movs[\"app_start_date\"])\n",
    "    \n",
    "    print \"Generating LTU/Non-LTU labels\"\n",
    "    cancelled_12mo = apps_cancelled_within_n_months(movs)\n",
    "    placed_12mo = apps_placed_within_n_months(movs)\n",
    "    \n",
    "    non_ltu_apps = np.unique(np.append(cancelled_12mo,placed_12mo))\n",
    "    apps['ltu'] = np.logical_not(apps['table_index'].isin(non_ltu_apps))\n",
    "    last_data_date = max(apps['app_start_date'])\n",
    "    apps.loc[difftime_in_months(last_data_date,apps['app_start_date']) < 12,'ltu'] = False\n",
    "    \n",
    "    return apps\n",
    "\n",
    "def get_ltu_label_on_date(apps,movs,date,ltu_length):\n",
    "    apps_movs = pandas_utils.filter_by_time_range(movs[movs['application_id'].isin(apps['table_index'])],'movement_event_date',None,date)\n",
    "    app_date_dict = dict(zip(apps[\"table_index\"],apps[\"app_start_date\"]))\n",
    "    apps_movs[\"app_start_date\"] = apps_movs[\"application_id\"].map(app_date_dict)\n",
    "    apps_movs[\"months_after_app\"] = difftime_in_months(apps_movs[\"movement_event_date\"],apps_movs[\"app_start_date\"])\n",
    "    \n",
    "    print \"Generating LTU/Non-LTU labels\"\n",
    "    cancelled_12mo = apps_cancelled_within_n_months(apps_movs,ltu_length)\n",
    "    placed_12mo = apps_placed_within_n_months(apps_movs,ltu_length)\n",
    "    \n",
    "    non_ltu_apps = np.unique(np.append(cancelled_12mo,placed_12mo))\n",
    "    apps['ltu'] = np.logical_not(apps['table_index'].isin(non_ltu_apps))\n",
    "    apps.loc[difftime_in_months(date,apps['app_start_date']) < ltu_length,'ltu'] = False\n",
    "    \n",
    "    return apps[['table_index','ltu']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting train/test datasets\n",
    "train_apps,test_apps,train_movs = split_train_test_apps(apps,movs,test_st_date,train_st_date,ltu_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating LTU/Non-LTU labels\n",
      "Generating LTU/Non-LTU labels\n"
     ]
    }
   ],
   "source": [
    "#Generate LTU Label\n",
    "train_labels = get_ltu_label_on_date(train_apps,movs,test_st_date,ltu_length)\n",
    "test_labels = get_ltu_label_on_date(test_apps,movs,test_st_date + test_window_size,ltu_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extend data\n",
    "train_extended = extend_data(train_apps,movs,train_labels,test_st_date,pd.Timedelta('30D'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_demographics(feature_matrix, apps):\n",
    "    #Create DF with the demographic features per application_id\n",
    "    demo_df = apps[[\"table_index\"]]\n",
    "    \n",
    "    demo_df[\"age\"] = apps[\"ute_idade\"] #redo age variable to make dyanamic?\n",
    "    demo_df[\"gender\"] = apps[\"sexo\"]\n",
    "    demo_df[\"is_re_registriation\"] = apps[\"candidatura_rinsc\"]\n",
    "    demo_df[\"soc_ben\"] = apps[\"sub_rsi\"]\n",
    "    demo_df[\"age2\"]=demo_df[\"age\"]**2\n",
    "    demo_df[\"age\"]=preprocessing.scale(demo_df[\"age\"].astype(float),copy=False)\n",
    "    demo_df[\"age2\"]=preprocessing.scale(demo_df[\"age2\"].astype(float),copy=False)\n",
    "    demo_df[\"season\"]=apps[\"app_start_date\"].apply(findSeason)\n",
    "    demo_df[\"nationality\"]=apps[\"cnacionalidade\"].apply(isPortuguese)\n",
    "    demo_df[\"education\"]=apps[\"chabilitacao_escolar\"].apply(createEducationBuckets) \n",
    "    demo_df[\"first_job\"]=apps[\"dcategoria\"].apply(lookingForFirstJob)\n",
    "    demo_df[\"time_since_exit\"]=(pd.to_datetime(apps[\"candidatura_data\"])-pd.to_datetime(apps[\"reinscricao_ult_saida_data\"])).dt.days\n",
    "    demo_df[\"time_since_exit\"].fillna(500,inplace=True)\n",
    "    demo_df[\"time_since_exit\"]=pd.to_numeric(demo_df[\"time_since_exit\"])\n",
    "    demo_df[\"time_since_exit\"]=preprocessing.scale(demo_df[\"time_since_exit\"], copy=False)\n",
    "    demo_df[\"is_disabled\"]=apps[\"cdeficiencia\"].apply(lambda x: \"N\" if x==0 else \"S\")\n",
    "    demo_df[\"civil_status\"]=apps[\"ute_estado_civil\"].apply(civilStatus)\n",
    "    demo_df[\"has_course_area\"]=apps[\"darea_curso_tabela_em_activo\"]\n",
    "    demo_df[\"has_course_area\"].fillna(0,inplace=True)\n",
    "    demo_df[\"has_course_area\"]=demo_df[\"has_course_area\"].apply(lambda x: \"S\" if x==0 else \"N\")\n",
    "    demo_df[\"has_prof_area\"]=apps[\"darea_formacao_tabela_em_activo\"]\n",
    "    demo_df[\"has_prof_area\"].fillna(0,inplace=True)\n",
    "    demo_df[\"has_prof_area\"]=demo_df[\"has_prof_area\"].apply(lambda x: \"S\" if x==0 else \"N\")\n",
    "    demo_df[\"age_category\"]=demo_df[\"age\"].apply(ageBucket)\n",
    "    demo_df[\"number_dependents\"]=apps[\"ute_nr_pessoas_cargo\"].astype(float).fillna(0)\n",
    "    demo_df[\"number_dependents\"]=preprocessing.scale(demo_df[\"number_dependents\"], copy=False)\n",
    "    demo_df[\"experience_intended_prof\"]=apps[\"candidatura_prof_pret_tempo_pratica\"].astype(float).fillna(0)\n",
    "    demo_df[\"experience_intended_prof\"]=preprocessing.scale(demo_df[\"experience_intended_prof\"], copy=False)\n",
    "    demo_df[\"experience_prev_prof\"]=apps[\"sit_anterior_prof_tempo_pratica\"].astype(float).fillna(0)\n",
    "    demo_df[\"experience_prev_prof\"]=preprocessing.scale(demo_df[\"experience_prev_prof\"], copy=False) \n",
    "    demo_df[\"intended_prof_1\"]=apps[\"cnp_pretendida\"].apply(findMainBucket)\n",
    "    demo_df[\"intended_prof_2\"]=apps[\"cpp_pretendida\"].apply(findMainBucket)\n",
    "    demo_df[\"intended_prof\"]=np.where(pd.isnull(demo_df[\"intended_prof_1\"]),demo_df[\"intended_prof_2\"],demo_df[\"intended_prof_1\"])\n",
    "    del demo_df[\"intended_prof_1\"]\n",
    "    del demo_df[\"intended_prof_2\"]  \n",
    "    demo_df[\"previous_prof_1\"]=apps[\"cnp_anterior\"].apply(findMainBucket)\n",
    "    demo_df[\"previous_prof_2\"]=apps[\"cpp_anterior\"].apply(findMainBucket)\n",
    "    demo_df[\"previous_prof\"]=np.where(pd.isnull(demo_df[\"previous_prof_1\"]),demo_df[\"previous_prof_2\"],demo_df[\"previous_prof_1\"])\n",
    "    del demo_df[\"previous_prof_1\"]\n",
    "    del demo_df[\"previous_prof_2\"]   \n",
    "    demo_df[\"training_area\"]= apps[\"carea_formacao_tabela_em_activo\"].apply(findMainEducation)   \n",
    "    #demo_df['app_start_date'] = pd.to_datetime(apps['app_start_date'])  #already in the extended data\n",
    "    demo_df['preferred_location']=apps['candidatura_local_trabalho'].apply(preferredJobRegion)\n",
    "    demo_df['app_year'] = apps['app_start_date'].apply(lambda x: x.year)\n",
    "    demo_df['app_month'] = apps['app_start_date'].apply(lambda x: x.month)\n",
    "    demo_df['employment_plan'] = apps['ute_plano_emprego'].apply(employmentPlan)\n",
    "    demo_df['prev_employment_plan'] = apps['ute_plano_emprego_anterior'].apply(employmentPlan)\n",
    "    demo_df['app_origin'] = apps['candidatura_origem'].apply(applicationOrigin)\n",
    "    demo_df['intended_regime'] = apps['dregime_contrato_pretendido'].apply(intendedRegime)\n",
    "    demo_df['dependents_bucket'] = apps['ute_nr_pessoas_cargo'].astype(float).apply(dependentsBucket)\n",
    "    demo_df['exp_intended_prof_buckets'] = apps['candidatura_prof_pret_tempo_pratica'].astype(float).apply(experienceBuckets)\n",
    "    demo_df['exp_previous_prof_buckets'] = apps['sit_anterior_prof_tempo_pratica'].astype(float).apply(experienceBuckets)\n",
    "    \n",
    "    #map to feature matrix using application ID\n",
    "    feature_matrix = pd.merge(feature_matrix, demo_df, how='left', left_on='application_id', left_index=True, right_on='table_index')\n",
    "    return feature_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_matrix(extended_data, apps_cropped, movs_cropped, feature_set_list):\n",
    "    #map movements to application start date\n",
    "    #app_date_dict = dict(zip(extended_data[\"table_index\"],extended_data[\"app_start_date\"]))\n",
    "    #movs[\"app_start_date\"] = movs[\"application_id\"].map(app_date_dict)\n",
    "\n",
    "    print \"Generating matrix base\" #generate basic matrix including appID, application date, months so far, and label\n",
    "    feature_matrix = extended_data.copy()\n",
    "    if \"demographics\" in feature_set_list:\n",
    "        print \"Adding demographic features\"\n",
    "        feature_matrix = add_demographics(feature_matrix, apps_cropped)\n",
    "    \n",
    "    if \"dynamic\" in feature_set_list:\n",
    "        print \"Adding dynamic features\"\n",
    "        feature_matrix = add_dynamic_features(feature_matrix, movs_cropped)\n",
    "    \n",
    "    #Removing Irrelevant features and create dummies for categorical variables\n",
    "    irrelevant_features = ['application_id','app_start_date','ref_date']\n",
    "    #feature_matrix.drop(irrelevant_features,1,inplace=True)\n",
    "    #feature_matrix = pd.get_dummies(feature_matrix,drop_first=True)\n",
    "    \n",
    "    return feature_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_dynamic_features(feature_matrix, movs):\n",
    "    feature_matrix['time_so_far'] = feature_matrix['ref_date']-feature_matrix['app_start_date']\n",
    "    feature_matrix['months_so_far'] = feature_matrix['time_so_far']/np.timedelta64(1,'M')\n",
    "    \n",
    "    for index, row in feature_matrix.iterrows():\n",
    "        feature_matrix.loc[index,'moves_so_far']=len(movs[(movs['application_id']==row['application_id'])\\\n",
    "                                                          & (movs['movement_event_date']<row['ref_date'])])\n",
    "#     for index in feature_matrix.index:\n",
    "#         application_id = feature_matrix.loc[index,'application_id']\n",
    "#         ref_date = feature_matrix.loc[index,'ref_date']\n",
    "#         print movs[(movs['application_id']==application_id)]) #&\\\n",
    "         #(movs['movement_type']==\"intervention\") &\\\n",
    "         #(movs['movement_event_date']<ref_date)])\n",
    "    #selected_movs = movs[movs['application_id'].isin(feature_matrix['application_id'])]\n",
    "    #model_utils.filter_by_time_range(movs,'movement_event_date',None,test_date)\n",
    "    #feature_matrix['months_so_far'] = feature_matrix['app_start_date'].apply(lambda x: monthdelta(x,ref_date))\n",
    "    ##NEED TO FIX THESE\n",
    "#     mov_counts_dict = dict(movs.groupby('application_id').movement_type.value_counts().unstack())\n",
    "#     feature_matrix['interventions_so_far'] = feature_matrix['application_id'].apply(lambda x: mov_counts_dict['intervention'][x])\n",
    "#     feature_matrix['interventions_so_far'].fillna(0,inplace=True)\n",
    "#     feature_matrix['interviews_so_far'] =  feature_matrix['application_id'].apply(lambda x: mov_counts_dict['interview'][x])\n",
    "#     feature_matrix['interviews_so_far'].fillna(0,inplace=True)\n",
    "#     feature_matrix['convocations_so_far'] =  feature_matrix['application_id'].apply(lambda x: mov_counts_dict['convocation'][x])\n",
    "#     feature_matrix['convocations_so_far'].fillna(0,inplace=True)\n",
    "    #feature_matrix['apps_in_last_3_yrs'] need to take in previous app data\n",
    "    return feature_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating matrix base\n",
      "Adding dynamic features\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-3947660f0d29>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchained_assignment\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_extended\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_apps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_movs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"dynamic\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-24-ff54bb7544dd>\u001b[0m in \u001b[0;36mgenerate_matrix\u001b[0;34m(extended_data, apps_cropped, movs_cropped, feature_set_list)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m\"dynamic\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfeature_set_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;32mprint\u001b[0m \u001b[0;34m\"Adding dynamic features\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mfeature_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madd_dynamic_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmovs_cropped\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;31m#Removing Irrelevant features and create dummies for categorical variables\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-25-a22b12bbc293>\u001b[0m in \u001b[0;36madd_dynamic_features\u001b[0;34m(feature_matrix, movs)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfeature_matrix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mfeature_matrix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'moves_so_far'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmovs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmovs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'application_id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'application_id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m                                                          \u001b[0;34m&\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmovs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'movement_event_date'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ref_date'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;31m#     for index in feature_matrix.index:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m#         application_id = feature_matrix.loc[index,'application_id']\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/lib/python2.7/site-packages/pandas/core/indexing.pyc\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m    177\u001b[0m             \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_setitem_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setitem_with_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_has_valid_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/lib/python2.7/site-packages/pandas/core/indexing.pyc\u001b[0m in \u001b[0;36m_setitem_with_indexer\u001b[0;34m(self, indexer, value)\u001b[0m\n\u001b[1;32m    586\u001b[0m                 \u001b[0;31m# scalar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 588\u001b[0;31m                     \u001b[0msetter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    589\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/lib/python2.7/site-packages/pandas/core/indexing.pyc\u001b[0m in \u001b[0;36msetter\u001b[0;34m(item, v)\u001b[0m\n\u001b[1;32m    510\u001b[0m                     \u001b[0;31m# set the item, possibly having a dtype change\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    511\u001b[0m                     \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_consolidate_inplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 512\u001b[0;31m                     \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    513\u001b[0m                     \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m                     \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_update_cacher\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclear\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/lib/python2.7/site-packages/pandas/core/generic.pyc\u001b[0m in \u001b[0;36mcopy\u001b[0;34m(self, deep)\u001b[0m\n\u001b[1;32m   3431\u001b[0m         \"\"\"\n\u001b[1;32m   3432\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdeep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3433\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3434\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3435\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__copy__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/lib/python2.7/site-packages/pandas/core/series.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, dtype, name, copy, fastpath)\u001b[0m\n\u001b[1;32m    173\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m             \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m                     \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "pd.options.mode.chained_assignment = None\n",
    "train_matrix = generate_matrix(train_extended,train_apps,train_movs,[\"dynamic\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>application_id</th>\n",
       "      <th>ref_date</th>\n",
       "      <th>moves_so_far</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>82893</th>\n",
       "      <td>82894</td>\n",
       "      <td>2015-08-06</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82893</th>\n",
       "      <td>82894</td>\n",
       "      <td>2015-09-06</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82893</th>\n",
       "      <td>82894</td>\n",
       "      <td>2015-10-06</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83240</th>\n",
       "      <td>83241</td>\n",
       "      <td>2015-09-24</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83240</th>\n",
       "      <td>83241</td>\n",
       "      <td>2015-10-24</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84834</th>\n",
       "      <td>84835</td>\n",
       "      <td>2015-07-23</td>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84834</th>\n",
       "      <td>84835</td>\n",
       "      <td>2015-08-23</td>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84834</th>\n",
       "      <td>84835</td>\n",
       "      <td>2015-09-23</td>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84834</th>\n",
       "      <td>84835</td>\n",
       "      <td>2015-10-23</td>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84834</th>\n",
       "      <td>84835</td>\n",
       "      <td>2015-11-23</td>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84834</th>\n",
       "      <td>84835</td>\n",
       "      <td>2015-12-23</td>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85491</th>\n",
       "      <td>85492</td>\n",
       "      <td>2015-10-23</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86057</th>\n",
       "      <td>86058</td>\n",
       "      <td>2015-10-23</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86057</th>\n",
       "      <td>86058</td>\n",
       "      <td>2015-11-23</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86057</th>\n",
       "      <td>86058</td>\n",
       "      <td>2015-12-23</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86057</th>\n",
       "      <td>86058</td>\n",
       "      <td>2016-01-23</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86057</th>\n",
       "      <td>86058</td>\n",
       "      <td>2016-02-23</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86057</th>\n",
       "      <td>86058</td>\n",
       "      <td>2016-03-23</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86057</th>\n",
       "      <td>86058</td>\n",
       "      <td>2016-04-23</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98717</th>\n",
       "      <td>98718</td>\n",
       "      <td>2015-06-23</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98717</th>\n",
       "      <td>98718</td>\n",
       "      <td>2015-07-23</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98717</th>\n",
       "      <td>98718</td>\n",
       "      <td>2015-08-23</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98717</th>\n",
       "      <td>98718</td>\n",
       "      <td>2015-09-23</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98717</th>\n",
       "      <td>98718</td>\n",
       "      <td>2015-10-23</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98717</th>\n",
       "      <td>98718</td>\n",
       "      <td>2015-11-23</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98978</th>\n",
       "      <td>98979</td>\n",
       "      <td>2015-06-23</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98978</th>\n",
       "      <td>98979</td>\n",
       "      <td>2015-07-23</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98978</th>\n",
       "      <td>98979</td>\n",
       "      <td>2015-08-23</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98978</th>\n",
       "      <td>98979</td>\n",
       "      <td>2015-09-23</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98978</th>\n",
       "      <td>98979</td>\n",
       "      <td>2015-10-23</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113807</th>\n",
       "      <td>113808</td>\n",
       "      <td>2015-09-04</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113807</th>\n",
       "      <td>113808</td>\n",
       "      <td>2015-10-04</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113807</th>\n",
       "      <td>113808</td>\n",
       "      <td>2015-11-04</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114103</th>\n",
       "      <td>114104</td>\n",
       "      <td>2015-07-01</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114103</th>\n",
       "      <td>114104</td>\n",
       "      <td>2015-08-01</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114103</th>\n",
       "      <td>114104</td>\n",
       "      <td>2015-09-01</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114103</th>\n",
       "      <td>114104</td>\n",
       "      <td>2015-10-01</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114103</th>\n",
       "      <td>114104</td>\n",
       "      <td>2015-11-01</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114103</th>\n",
       "      <td>114104</td>\n",
       "      <td>2015-12-01</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116705</th>\n",
       "      <td>116706</td>\n",
       "      <td>2015-11-18</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116705</th>\n",
       "      <td>116706</td>\n",
       "      <td>2015-12-18</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116705</th>\n",
       "      <td>116706</td>\n",
       "      <td>2016-01-18</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116705</th>\n",
       "      <td>116706</td>\n",
       "      <td>2016-02-18</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116765</th>\n",
       "      <td>116766</td>\n",
       "      <td>2015-06-26</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116765</th>\n",
       "      <td>116766</td>\n",
       "      <td>2015-07-26</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116765</th>\n",
       "      <td>116766</td>\n",
       "      <td>2015-08-26</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116765</th>\n",
       "      <td>116766</td>\n",
       "      <td>2015-09-26</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116765</th>\n",
       "      <td>116766</td>\n",
       "      <td>2015-10-26</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116765</th>\n",
       "      <td>116766</td>\n",
       "      <td>2015-11-26</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116765</th>\n",
       "      <td>116766</td>\n",
       "      <td>2015-12-26</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116765</th>\n",
       "      <td>116766</td>\n",
       "      <td>2016-01-26</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116765</th>\n",
       "      <td>116766</td>\n",
       "      <td>2016-02-26</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124710</th>\n",
       "      <td>124711</td>\n",
       "      <td>2015-05-29</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124710</th>\n",
       "      <td>124711</td>\n",
       "      <td>2015-06-29</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124710</th>\n",
       "      <td>124711</td>\n",
       "      <td>2015-07-29</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124710</th>\n",
       "      <td>124711</td>\n",
       "      <td>2015-08-29</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124710</th>\n",
       "      <td>124711</td>\n",
       "      <td>2015-09-29</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124710</th>\n",
       "      <td>124711</td>\n",
       "      <td>2015-10-29</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124710</th>\n",
       "      <td>124711</td>\n",
       "      <td>2015-11-29</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124710</th>\n",
       "      <td>124711</td>\n",
       "      <td>2015-12-29</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26222 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        application_id   ref_date  moves_so_far\n",
       "82893            82894 2015-08-06           9.0\n",
       "82893            82894 2015-09-06           9.0\n",
       "82893            82894 2015-10-06           9.0\n",
       "83240            83241 2015-09-24           6.0\n",
       "83240            83241 2015-10-24           6.0\n",
       "84834            84835 2015-07-23          35.0\n",
       "84834            84835 2015-08-23          35.0\n",
       "84834            84835 2015-09-23          35.0\n",
       "84834            84835 2015-10-23          35.0\n",
       "84834            84835 2015-11-23          35.0\n",
       "84834            84835 2015-12-23          35.0\n",
       "85491            85492 2015-10-23           0.0\n",
       "86057            86058 2015-10-23          12.0\n",
       "86057            86058 2015-11-23          12.0\n",
       "86057            86058 2015-12-23          12.0\n",
       "86057            86058 2016-01-23          12.0\n",
       "86057            86058 2016-02-23          12.0\n",
       "86057            86058 2016-03-23          12.0\n",
       "86057            86058 2016-04-23          12.0\n",
       "98717            98718 2015-06-23           9.0\n",
       "98717            98718 2015-07-23           9.0\n",
       "98717            98718 2015-08-23           9.0\n",
       "98717            98718 2015-09-23           9.0\n",
       "98717            98718 2015-10-23           9.0\n",
       "98717            98718 2015-11-23           9.0\n",
       "98978            98979 2015-06-23          11.0\n",
       "98978            98979 2015-07-23          11.0\n",
       "98978            98979 2015-08-23          11.0\n",
       "98978            98979 2015-09-23          11.0\n",
       "98978            98979 2015-10-23          11.0\n",
       "...                ...        ...           ...\n",
       "113807          113808 2015-09-04           5.0\n",
       "113807          113808 2015-10-04           5.0\n",
       "113807          113808 2015-11-04           5.0\n",
       "114103          114104 2015-07-01           9.0\n",
       "114103          114104 2015-08-01           9.0\n",
       "114103          114104 2015-09-01           9.0\n",
       "114103          114104 2015-10-01           9.0\n",
       "114103          114104 2015-11-01           9.0\n",
       "114103          114104 2015-12-01           9.0\n",
       "116705          116706 2015-11-18           8.0\n",
       "116705          116706 2015-12-18           8.0\n",
       "116705          116706 2016-01-18           8.0\n",
       "116705          116706 2016-02-18           8.0\n",
       "116765          116766 2015-06-26           2.0\n",
       "116765          116766 2015-07-26           2.0\n",
       "116765          116766 2015-08-26           2.0\n",
       "116765          116766 2015-09-26           2.0\n",
       "116765          116766 2015-10-26           2.0\n",
       "116765          116766 2015-11-26           2.0\n",
       "116765          116766 2015-12-26           2.0\n",
       "116765          116766 2016-01-26           2.0\n",
       "116765          116766 2016-02-26           2.0\n",
       "124710          124711 2015-05-29           7.0\n",
       "124710          124711 2015-06-29           7.0\n",
       "124710          124711 2015-07-29           7.0\n",
       "124710          124711 2015-08-29           7.0\n",
       "124710          124711 2015-09-29           7.0\n",
       "124710          124711 2015-10-29           7.0\n",
       "124710          124711 2015-11-29           7.0\n",
       "124710          124711 2015-12-29           7.0\n",
       "\n",
       "[26222 rows x 3 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_matrix[['application_id','ref_date','moves_so_far']].sort_values(['application_id','ref_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_movs['movement_event_date'][679141]<train_matrix['ref_date'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2015-04-30 00:00:00')"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_matrix['ref_date'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ute_id</th>\n",
       "      <th>movement_event_date</th>\n",
       "      <th>application_id</th>\n",
       "      <th>movement_type</th>\n",
       "      <th>movement_subtype</th>\n",
       "      <th>movement_result</th>\n",
       "      <th>movement_index</th>\n",
       "      <th>app_start_date</th>\n",
       "      <th>months_after_app</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>679141</th>\n",
       "      <td>3917598</td>\n",
       "      <td>2015-04-30</td>\n",
       "      <td>99624</td>\n",
       "      <td>application</td>\n",
       "      <td>DESEMPREGADO-NOVO EMPREGO</td>\n",
       "      <td></td>\n",
       "      <td>99624</td>\n",
       "      <td>2015-04-30</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>606593</th>\n",
       "      <td>3697365</td>\n",
       "      <td>2015-04-30</td>\n",
       "      <td>92918</td>\n",
       "      <td>convocation</td>\n",
       "      <td>CONVOCATÃRIA GIP</td>\n",
       "      <td>NÃO COMPARECEU INJUSTIFICADAMENTE</td>\n",
       "      <td>200980</td>\n",
       "      <td>2014-01-29</td>\n",
       "      <td>14.981827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>606592</th>\n",
       "      <td>3697365</td>\n",
       "      <td>2015-04-30</td>\n",
       "      <td>92918</td>\n",
       "      <td>convocation</td>\n",
       "      <td>CONVOCATÃRIA GIP</td>\n",
       "      <td>NÃO COMPARECEU INJUSTIFICADAMENTE</td>\n",
       "      <td>200979</td>\n",
       "      <td>2014-01-29</td>\n",
       "      <td>14.981827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43241</th>\n",
       "      <td>367021</td>\n",
       "      <td>2015-04-30</td>\n",
       "      <td>92906</td>\n",
       "      <td>interview</td>\n",
       "      <td>588551128</td>\n",
       "      <td>RECUSA DA ENTIDADE EMPREGADORA - NÃO MARCAÃÃ...</td>\n",
       "      <td>127692</td>\n",
       "      <td>2014-10-08</td>\n",
       "      <td>6.702396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>825828</th>\n",
       "      <td>4347531</td>\n",
       "      <td>2015-04-30</td>\n",
       "      <td>86722</td>\n",
       "      <td>category_change</td>\n",
       "      <td>DESEMPREGADO-NOVO EMPREGO</td>\n",
       "      <td>DESEMP NOVO EMPREGO - INDISPONÃVEL</td>\n",
       "      <td>92090</td>\n",
       "      <td>2014-04-11</td>\n",
       "      <td>12.616275</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ute_id movement_event_date  application_id    movement_type  \\\n",
       "679141  3917598          2015-04-30           99624      application   \n",
       "606593  3697365          2015-04-30           92918      convocation   \n",
       "606592  3697365          2015-04-30           92918      convocation   \n",
       "43241    367021          2015-04-30           92906        interview   \n",
       "825828  4347531          2015-04-30           86722  category_change   \n",
       "\n",
       "                 movement_subtype  \\\n",
       "679141  DESEMPREGADO-NOVO EMPREGO   \n",
       "606593          CONVOCATÃRIA GIP   \n",
       "606592          CONVOCATÃRIA GIP   \n",
       "43241                   588551128   \n",
       "825828  DESEMPREGADO-NOVO EMPREGO   \n",
       "\n",
       "                                          movement_result  movement_index  \\\n",
       "679141                                                              99624   \n",
       "606593                 NÃO COMPARECEU INJUSTIFICADAMENTE          200980   \n",
       "606592                 NÃO COMPARECEU INJUSTIFICADAMENTE          200979   \n",
       "43241   RECUSA DA ENTIDADE EMPREGADORA - NÃO MARCAÃÃ...          127692   \n",
       "825828                DESEMP NOVO EMPREGO - INDISPONÃVEL           92090   \n",
       "\n",
       "       app_start_date  months_after_app  \n",
       "679141     2015-04-30          0.000000  \n",
       "606593     2014-01-29         14.981827  \n",
       "606592     2014-01-29         14.981827  \n",
       "43241      2014-10-08          6.702396  \n",
       "825828     2014-04-11         12.616275  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_movs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_movs[(train_movs['application_id']==84835)&(train_movs['movement_event_date']<train_matrix['ref_date'].iloc[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.merge(left = train_extended, train_movs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "extended_dates = train_extended[['application_id','ref_date']].rename(columns={'ref_date':'movement_event_date'})\n",
    "extended_dates['movement_type'] = 'ref_date'\n",
    "mov_dates = train_movs[['application_id','movement_type','movement_event_date']]\n",
    "extended_movs = pd.concat([extended_dates,mov_dates]).sort_values(by=['application_id','movement_event_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "interview_count = 0\n",
    "convocation_count = 0\n",
    "intervention_count = 0\n",
    "previous_id = -1\n",
    "for index,row in extended_movs.iterrows():\n",
    "    if row['application_id']!=previous_id:\n",
    "        interview_count = 0\n",
    "        convocation_count = 0\n",
    "        intervention_count = 0 \n",
    "    if row['movement_type'] == \"interview\":\n",
    "        interview_count +=1\n",
    "    elif row['movement_type'] == \"convocation\":\n",
    "        convocation_count +=1\n",
    "    elif row['movement_type'] == \"intervention\":\n",
    "        intervention_count +=1\n",
    "    elif row['movement_type'] == \"ref_date\":\n",
    "        row['interviews_so_far'] = interview_count\n",
    "        row['convocations_so_far'] = convocation_count\n",
    "        row['interventions_so_far'] = intervention_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "125231"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(extended_movs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_extended.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_matrix.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mov_counts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mov_counts = train_movs[['application_id','movement_type','movement_event_date']].sort_values(by=['application_id',\"movement_type\",\"movement_event_date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mov_counts[mov_counts['application_id']==86722]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#old version for reference\n",
    "def generate_matrix_old(clean_apps,clean_movs,feature_set_name,ref_date,feature_file_path=None):\n",
    "\n",
    "    app_date_dict = dict(zip(clean_apps[\"table_index\"],clean_apps[\"app_start_date\"]))\n",
    "    clean_movs[\"app_start_date\"] = clean_movs[\"application_id\"].map(app_date_dict)\n",
    "    \n",
    "    feature_matrix = clean_apps[[\"table_index\",\"app_start_date\",\"ltu\",\"ute_idade\",\"sexo\",\"candidatura_rinsc\",\"sub_rsi\"]].drop_duplicates(subset='table_index')\n",
    "    feature_matrix.rename(columns={\"table_index\":\"application_id\", \"ute_idade\": \"age\", \"sexo\":\"gender\",\\\n",
    "                              \"candidatura_rinsc\":\"is_re_registriation\",\"sub_rsi\":\"soc_ben\"}, inplace=True)\n",
    "    \n",
    "    print \"Building model feature matrix\"\n",
    "    feature_matrix[\"age2\"]=feature_matrix[\"age\"]**2\n",
    "    feature_matrix[\"age\"]=preprocessing.scale(feature_matrix[\"age\"].astype(float),copy=False)\n",
    "    feature_matrix[\"age2\"]=preprocessing.scale(feature_matrix[\"age2\"].astype(float),copy=False)\n",
    "    feature_matrix[\"season\"]=clean_apps[\"app_start_date\"].apply(findSeason)\n",
    "    feature_matrix[\"nationality\"]=clean_apps[\"cnacionalidade\"].apply(isPortuguese)\n",
    "    feature_matrix[\"education\"]=clean_apps[\"chabilitacao_escolar\"].apply(createEducationBuckets) \n",
    "    feature_matrix[\"first_job\"]=clean_apps[\"dcategoria\"].apply(lookingForFirstJob)\n",
    "    feature_matrix[\"time_since_exit\"]=(pd.to_datetime(clean_apps[\"candidatura_data\"])-pd.to_datetime(clean_apps[\"reinscricao_ult_saida_data\"])).dt.days\n",
    "    feature_matrix[\"time_since_exit\"].fillna(500,inplace=True)\n",
    "    feature_matrix[\"time_since_exit\"]=pd.to_numeric(feature_matrix[\"time_since_exit\"])\n",
    "    feature_matrix[\"time_since_exit\"]=preprocessing.scale(feature_matrix[\"time_since_exit\"], copy=False)\n",
    "    feature_matrix[\"is_disabled\"]=clean_apps[\"cdeficiencia\"].apply(lambda x: \"N\" if x==0 else \"S\")\n",
    "    feature_matrix[\"civil_status\"]=clean_apps[\"ute_estado_civil\"].apply(civilStatus)\n",
    "    feature_matrix[\"has_course_area\"]=clean_apps[\"darea_curso_tabela_em_activo\"]\n",
    "    feature_matrix[\"has_course_area\"].fillna(0,inplace=True)\n",
    "    feature_matrix[\"has_course_area\"]=feature_matrix[\"has_course_area\"].apply(lambda x: \"S\" if x==0 else \"N\")\n",
    "    feature_matrix[\"has_prof_area\"]=clean_apps[\"darea_formacao_tabela_em_activo\"]\n",
    "    feature_matrix[\"has_prof_area\"].fillna(0,inplace=True)\n",
    "    feature_matrix[\"has_prof_area\"]=feature_matrix[\"has_prof_area\"].apply(lambda x: \"S\" if x==0 else \"N\")\n",
    "    feature_matrix[\"age_category\"]=feature_matrix[\"age\"].apply(ageBucket)\n",
    "    feature_matrix[\"number_dependents\"]=clean_apps[\"ute_nr_pessoas_cargo\"].astype(float).fillna(0)\n",
    "    feature_matrix[\"number_dependents\"]=preprocessing.scale(feature_matrix[\"number_dependents\"], copy=False)\n",
    "    feature_matrix[\"experience_intended_prof\"]=clean_apps[\"candidatura_prof_pret_tempo_pratica\"].astype(float).fillna(0)\n",
    "    feature_matrix[\"experience_intended_prof\"]=preprocessing.scale(feature_matrix[\"experience_intended_prof\"], copy=False)\n",
    "    feature_matrix[\"experience_prev_prof\"]=clean_apps[\"sit_anterior_prof_tempo_pratica\"].astype(float).fillna(0)\n",
    "    feature_matrix[\"experience_prev_prof\"]=preprocessing.scale(feature_matrix[\"experience_prev_prof\"], copy=False) \n",
    "    feature_matrix[\"intended_prof_1\"]=clean_apps[\"cnp_pretendida\"].apply(findMainBucket)\n",
    "    feature_matrix[\"intended_prof_2\"]=clean_apps[\"cpp_pretendida\"].apply(findMainBucket)\n",
    "    feature_matrix[\"intended_prof\"]=np.where(pd.isnull(feature_matrix[\"intended_prof_1\"]),feature_matrix[\"intended_prof_2\"],feature_matrix[\"intended_prof_1\"])\n",
    "    del feature_matrix[\"intended_prof_1\"]\n",
    "    del feature_matrix[\"intended_prof_2\"]  \n",
    "    feature_matrix[\"previous_prof_1\"]=clean_apps[\"cnp_anterior\"].apply(findMainBucket)\n",
    "    feature_matrix[\"previous_prof_2\"]=clean_apps[\"cpp_anterior\"].apply(findMainBucket)\n",
    "    feature_matrix[\"previous_prof\"]=np.where(pd.isnull(feature_matrix[\"previous_prof_1\"]),feature_matrix[\"previous_prof_2\"],feature_matrix[\"previous_prof_1\"])\n",
    "    del feature_matrix[\"previous_prof_1\"]\n",
    "    del feature_matrix[\"previous_prof_2\"]   \n",
    "    feature_matrix[\"training_area\"]= clean_apps[\"carea_formacao_tabela_em_activo\"].apply(findMainEducation)   \n",
    "    feature_matrix['app_start_date'] = pd.to_datetime(feature_matrix['app_start_date'])\n",
    "    \n",
    "    feature_matrix['preferred_location']=clean_apps['candidatura_local_trabalho'].apply(preferredJobRegion)\n",
    "    feature_matrix['app_year'] = clean_apps.app_start_date.apply(lambda x: x.year)\n",
    "    feature_matrix['app_month'] = clean_apps.app_start_date.apply(lambda x: x.month)\n",
    "    feature_matrix['employment_plan'] = clean_apps.ute_plano_emprego.apply(employmentPlan)\n",
    "    feature_matrix['prev_employment_plan'] = clean_apps.ute_plano_emprego_anterior.apply(employmentPlan)\n",
    "    feature_matrix['app_origin'] = clean_apps.candidatura_origem.apply(applicationOrigin)\n",
    "    feature_matrix['intended_regime'] = clean_apps.dregime_contrato_pretendido.apply(intendedRegime)\n",
    "    feature_matrix['dependents_bucket'] = clean_apps.ute_nr_pessoas_cargo.astype(float).apply(dependentsBucket)\n",
    "    feature_matrix['exp_intended_prof_buckets'] = clean_apps.candidatura_prof_pret_tempo_pratica.astype(float).apply(experienceBuckets)\n",
    "    feature_matrix['exp_previous_prof_buckets'] = clean_apps.sit_anterior_prof_tempo_pratica.astype(float).apply(experienceBuckets)\n",
    "    \n",
    "    if feature_set_name==\"dynamic\":\n",
    "        feature_matrix['time_since_app'] = feature_matrix['app_start_date'].apply(lambda x: monthdelta(x,ref_date))\n",
    "        #feature_matrix['apps_in_last_3_yrs'] need to take in previous app data\n",
    "        mov_counts_dict = dict(clean_movs.groupby('application_id').movement_type.value_counts().unstack())\n",
    "        feature_matrix['interventions_so_far'] = feature_matrix['application_id'].apply(lambda x: mov_counts_dict['intervention'][x])\n",
    "        feature_matrix['interventions_so_far'].fillna(0,inplace=True)\n",
    "        feature_matrix['interviews_so_far'] =  feature_matrix['application_id'].apply(lambda x: mov_counts_dict['interview'][x])\n",
    "        feature_matrix['interviews_so_far'].fillna(0,inplace=True)\n",
    "        feature_matrix['convocations_so_far'] =  feature_matrix['application_id'].apply(lambda x: mov_counts_dict['convocation'][x])\n",
    "        feature_matrix['convocations_so_far'].fillna(0,inplace=True) \n",
    "\n",
    "\n",
    "    #Removing Irrelevant features and create dummies for categorical variables\n",
    "    irrelevant_features = ['app_start_date']\n",
    "    feature_matrix.drop(irrelevant_features,1,inplace=True)\n",
    "    feature_matrix = pd.get_dummies(feature_matrix,drop_first=True)\n",
    "   \n",
    "    if feature_file_path!=None: \n",
    "        print \"Writing model matrix to file\"\n",
    "        feature_matrix.to_csv(matrix_file_path, index=False, encoding='utf8')\n",
    "    return feature_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_matrix = generate_matrix(train_apps,train_movs,feature_set_name,train_end_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## getting time since app\n",
    "%matplotlib inline\n",
    "train_matrix.time_in_sys.value_counts().sort_index().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_matrix.iloc[:,0:10].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Getting actions since app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mov_counts = train_movs.groupby('application_id').movement_type.value_counts().unstack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mov_counts_dict = dict(mov_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mov_counts_dict['intervention'][86812]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_apps['interventions_so_far'] = train_apps['table_index'].\\\n",
    "apply(lambda x: mov_counts_dict['intervention'][x])\n",
    "train_apps['interventions_so_far'].fillna(0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_apps.interventions_so_far.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_matrix.ltu.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_apps.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Getting info from previous apps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_prev_app_st = split_date - train_timedelta - test_timedelta - pd.Timedelta(\"1095D\")\n",
    "test_prev_app_st = split_date - test_timedelta - pd.Timedelta(\"1095D\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_prev_app_st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_prev_apps_movs = model_utils.filter_by_time_range(movs,'movement_event_date',\\\n",
    "                                 train_prev_app_st,train_end_date)\n",
    "train_prev_apps_apps = model_utils.filter_by_time_range(apps,'app_start_date',\\\n",
    "                                 train_prev_app_st,train_end_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_prev_apps_apps.groupby('ute_id').table_index.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "apps.ute_nr_pessoas_cargo.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def experienceBuckets(n):\n",
    "    if pd.isnull(n):\n",
    "        return \"Unknown\"\n",
    "    elif n == 0:\n",
    "        return \"0\"\n",
    "    elif n<24:\n",
    "        return \"<2yr\"\n",
    "    elif n<60:\n",
    "        return \"<5yr\"\n",
    "    elif n<120:\n",
    "        return \"<10yr\"\n",
    "    elif n<240:\n",
    "        return \"<20yr\"\n",
    "    else:\n",
    "        return \"20+yr\"\n",
    "    \n",
    "#apps.candidatura_prof_pret_tempo_pratica.astype(float).value_counts(dropna=False).sort_index()\n",
    "apps.candidatura_prof_pret_tempo_pratica.astype(float).apply(experienceBuckets).value_counts()\n",
    "apps.sit_anterior_prof_tempo_pratica.astype(float).apply(experienceBuckets).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "apps.sit_anterior_prof_tempo_pratica.astype(float).apply(lambda x: x/12).plot.hist(bins=200, xlim=(0,30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "apps.sit_anterior_prof_tempo_pratica.value_counts().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print apps.cae_anterior.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "apps.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_matrix.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print train_matrix.ltu.value_counts(normalize=False)\n",
    "print test_matrix.ltu.value_counts(normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for column in train_matrix.columns:\n",
    "    print train_matrix[column].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_matrix.columns[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# scale to [0,1]?\n",
    "# dependents and experience into buckets?\n",
    "# what if categories don't appear in both train and test (like month)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features_list = ['age', 'age2', 'year', \\\n",
    "            'month', 'dynamic_time_since_app', 'dynamic_last_interview']\n",
    "feature_string = 'age age2 year month dynamic_time_since_app dynamic_last_int'\n",
    "\n",
    "#re.match('age',features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
